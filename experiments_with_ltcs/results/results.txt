FUTURE　| BIN_D |   inc |   MIXED MEM | LR       | SIZE |   TEST  | ID    | LOSS  | HPARAMS
1           0.5     2       0           9.7E-3      39      6.327   0409    ALL     0308     
1           0.5     2       0           6.45E-4     23      9.083   0410    ALL     0308 
1           0.5     2       1           7.28E-3     27      5.22    0504    ALL         
1           0.5     2       1           9.29E-4     39      4.31    0506    ALL
>　use mixed memory with large network SIZE
2           0.5     2       1           9.29E-4     39      8.39    0506    ALL                             1204        8.031
2           0.05    53      1           6.62E-3     28      0.4704  1203    ALL     0910            14-0	    
>　how is small binning?
2           0.05    53      1                          <LOSS ERROR> 1002    FUTURE  0911            
2           0.05    53      1           7.67E-4     20     0.8387   1103    FUTURE  1006            03-0    1202      0.6435
2           0.05    53      1           9.74E-3     24     0.7850   1104    FUTURE  1006            03-1    1201      0.5828
>  does other loss improve?       
4           0.05    53                  9.9E-3      40     0.7913   1110            1017               dcluser
> how is performance for predicting 0.05*4(0.2) sec?
TIMESTAMP    
2           0.05    53      1           0.022       36     0.4774   1208    ALL     
> does including timestamp improve performance?
OTHER TRAINSPLIT METHOD
2           0.05    53      1           9.74E-3     24     0.4774   1210    FUTURE 10-1 (hpar 1212 (error 1417) 14-1 future 5)
2           0.05    53      1           6.62E-3     28     0.4774   1211    ALL    14-0 (hpar 1213 (error 2024071418) 13-0 future 5)
>　how is performance with timestamp data ?


python forecast.py --size 36 --epochs 200 --gpus 1 --initial_lr 0.022 --dataset 
neuronlaser --future 2 --seq_len 32 --binwidth 0.05

